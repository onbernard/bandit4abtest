% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/policy_exp3.R
\name{policy_exp3}
\alias{policy_exp3}
\title{EXP3 algorithm}
\usage{
policy_exp3(visitor_reward, gamma = 0.05)
}
\arguments{
\item{visitor_reward}{Dataframe of numeric values}

\item{gamma}{Numeric value (optional)}
}
\value{
\itemize{ List of element:
 \item S         : Means and trials matrix
 \item choice    : Choice history vector
 \item proba     : Max probability history vector
 \item time      : Computation time
 \item theta_hat : Final estimated reward expectation of each arm
 \item theta     : Actual reward expectation of each arm
 \item weight    : Final probability weight of each arm}
}
\description{
Exponential  Weights  for  Exploration  and  Exploitation (EXP3)
 bandit strategy. It uses a list of weights which evolve according to arm's
 reward. The gamma parameter is a coefficient for balancing between
 exploitation and exploration.

 When processing a dataframe of reward representing a bandit, the function
 keeps track of each arm estimated reward expectation and number of trials.
 These are returned at the end of the computation in addition to the arm
 played and its associated probability at each iteration, the actual reward
 expectations, the computation time and the final weights values.

 See also  \code{\link{condition_for_exp3}}, \code{\link{generate_matrix_S}},
 and \code{\link{play_arm}}.

 Reward input is checked for correct dimensions and values. These must be
 binary (either numeric or integer ones and zeros) ! See
 \code{\link{bandit_reward_control}} and \code{\link{control_binary}}.
}
\examples{
## Generates 1000 numbers from 2 uniform distributions
set.seed(4434)
K1 <- rbinom(1000, 1, 0.6)
K2 <- rbinom(1000, 1, 0.7)
## Define a dataframe of rewards
visitor_reward <- as.data.frame( cbind(K1,K2) )
EXP3_alloc <- policy_exp3(visitor_reward)
EXP3_alloc$S
EXP3_alloc$time
EXP3_alloc$theta
EXP3_alloc$theta_hat

}
