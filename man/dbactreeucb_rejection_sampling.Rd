% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/dbactreeucb_rejection_sampling.R
\name{dbactreeucb_rejection_sampling}
\alias{dbactreeucb_rejection_sampling}
\title{dbactreeucb_rejection_sampling}
\usage{
dbactreeucb_rejection_sampling(
  dt,
  visitor_reward,
  K = ncol(visitor_reward),
  listSerie,
  listKCentroids,
  ctree_parameters_control = ctreeucb_parameters_control_default(dt, visitor_reward)
)
}
\arguments{
\item{dt}{Dataframe of integer numeric or factor values}

\item{visitor_reward}{Dataframe of integer or numeric values}

\item{listKCentroids}{List of Integer (Number of centroid)}

\item{is_reward_are_boolean}{logical value (optional)}

\item{learn_size}{number of items dedicated to the learnset (step 1)
(optional),}

\item{arm_for_learn}{arm dedicated to the learnset (step 1) (optional),}

\item{explanatory_variable}{= list of covariates (optional),}

\item{ctree_control_val}{Various parameters that control aspects of the
‘ctree’ fit (optional),}
}
\value{
\itemize{ List of element:
 \item choice: choices of UCB,
 \item proba: probability of the chosen arms,
 \item time: time of cumputation,
 \item theta_hat: coefficients estimated of each arm
 \item theta: real coefficients of each arm
 }
}
\description{
dbactreeucb_rejection_sampling automatically create homogeneous groups by a
conditional inference method (see  \code{\link{ctree}}) in a collection and
processing step before the A/B test (step 1). These groups are created
according to the objective of the test using information from previous items
(obtained rewards, items characteristics, temporal information, \ldots). This
information comes from the items that have already been subjected to the
original variation (A), implemented before the test. In the A/B test period
(step 2), the method defines as many non-contextual bandits  (see
\code{\link{UCB}}) with rejection sampling method as there are groups. Exclud
any choices which not corresponds to real exepriments in dataset. Each bandit
aims to find the optimal variation associated to its group. So, a new item is
firstly classed into a group and then the associated bandit chooses the
variation to which the item must be affected.
}
\examples{
size.tot = 9000
set.seed(4649)          # this makes the example exactly reproducible
# you have 4, largely uncorrelated predictors
x1 = runif(size.tot, min=0, max=10)
x2 = runif(size.tot, min=0, max=10)
x3 = runif(size.tot, min=0, max=10)
x4 = runif(size.tot, min=0, max=10)
dt = cbind(x1,x2,x3,x4)
arm_1 <-  as.vector(c(-1,9,-8,4))
K1 = crossprod(t(dt),arm_1)
arm_2 <-  as.vector(c(-1,2,1,0))
K2 = crossprod(t(dt),arm_2)
arm_3 <-  as.vector(c(-1,-5,1,10))
K3 = crossprod(t(dt),arm_3)
visitor_reward <-  data.frame(K1,K2,K3)
dt <- as.data.frame(dt)
size.tot = 9000
# Time series
alpha_list <- c(1,2,3)
beta_list <- c(0.5,0.1,-0.2)
theta_list <- c(0.8,0.2,0.5)
y <- as.data.frame(c(1))
colnames(y) = "ID"
temp=1
for (j in 1:3000){
 for (i in 1:length(alpha_list)){
   n = sample(1:100,1)
   t <- 1:n
   ts <- alpha_list[i] + beta_list[i] * t + arima.sim(list(
   ma = theta_list[i]), n = length(t))
   y[temp, "time_series"][[1]] <- list(ts)
   y[temp, "cluster"][[1]] <- i
   y$ID[temp] = temp
   temp = temp +1
 }
}
y <- y[sample(nrow(y)),]
dt <-  as.data.frame(cbind(x1,x2,x3,x4,y$time_series))
colnames(dt) <- c("x1","x2","x3","x4","time_series")
for(i in 1:nrow(dt)) {
 if(y$cluster[i] == 1) visitor_reward$K1[i] = 10
 if(y$cluster[i] == 2) visitor_reward$K2[i] = 20
 if(y$cluster[i] == 3) visitor_reward$K3[i] = 30
}
dt$cluster <- NULL
dt$x1 <- as.numeric(dt$x1)
dt$x2 <- as.numeric(dt$x2)
dt$x3 <- as.numeric(dt$x3)
dt$x4 <- as.numeric(dt$x4)
K=ncol(visitor_reward)
ctree_parameters_control=ctreeucb_parameters_control_default(dt,
visitor_reward)
listSerie = c("time_series")
listKCentroids=c(3)
dbactreeucb_rejection_sampling(dt,visitor_reward,K, listSerie, listKCentroids,
ctree_parameters_control)
}
