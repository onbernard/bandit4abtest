% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/policy_thompson_sampling.R
\name{condition_for_thompson_sampling}
\alias{condition_for_thompson_sampling}
\title{Condition for thompson sampling}
\usage{
condition_for_thompson_sampling(S, alpha = 1, beta = 1)
}
\arguments{
\item{S}{: Numerical matrix of means and trials}

\item{alpha, beta}{: Exploration parameters (optional)}
}
\value{
Vector containing each arm sample
}
\description{
Samples for each arm an average according to its probability
 distribution from the beta law (according to number of sucess and trials in
 S matrix). See also \code{\link{rbeta}}. Give the arm with the highest
 average score. Returns vector containing each arm sample.
}
\examples{
## Generates 1000 numbers from 2 uniform distributions
set.seed(4434)
K1 <- rbinom(1000, 1, 0.6)
K2 <- rbinom(1000, 1, 0.7)
## Define a dataframe of rewards
visitor_reward <- as.data.frame( cbind(K1,K2) )
## Number of arms
K=2
## Init the S Matrix
S <- generate_matrix_S(K)
S
## play arms uniformly
for(i in 1:nrow(visitor_reward)){
S <- play_arm(i,arm=(i\%\%K+1),S,visitor_reward)
}
## Results
S
## Choose next arm with thompson sampling policy
condition_for_thompson_sampling(S)
#Density
plot(density( rbeta(100, 1 + S[1,1]*S[2,1], 1 + S[2,1] - S[1,1]*S[2,1])))
plot(density( rbeta(100, 1 + S[1,2]*S[2,2], 1 + S[2,2] - S[1,2]*S[2,2])))

}
